{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fitdecode==0.10.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (r:\\program files\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (r:\\program files\\python37\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading fitdecode-0.10.0-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.9/90.9 kB ? eta 0:00:00\n",
      "Installing collected packages: fitdecode\n",
      "Successfully installed fitdecode-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fitdecode==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO improve docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons_directory = os.path.join(\".\", \"data\", \"json\")\n",
    "fit_directory = os.path.join(\".\", \"data\", \"fit\")\n",
    "current_directory = os.path.join(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_usable_fit_files(directory, extension):\n",
    "    \"\"\" Returns a list of fit files (in .json or in .fit format), avoiding some of the unnecesary files \"\"\"\n",
    "\n",
    "    return [fitfile.replace(\".json\", \"\") for fitfile in os.listdir(directory) if fitfile.endswith(extension) and \"inProgressActivity\" not in fitfile]\n",
    "\n",
    "def compare_files(usable_fit_files, existent_fit_files):\n",
    "    \"\"\" Compares two lists of files to know the difference between them \"\"\"\n",
    "\n",
    "    return list(set(usable_fit_files) - set(existent_fit_files))\n",
    "\n",
    "def obtain_new_files_in_folder_json_format():\n",
    "    \"\"\" Adds .fit files converted into JSON in a folder, adding only the non-existent ones after comparing the existent \"\"\"\n",
    "\n",
    "    os.makedirs(jsons_directory, exist_ok=True) #Does nothing if directory exists\n",
    "\n",
    "    usable_fit_files = search_usable_fit_files(directory=fit_directory, extension=\".fit\")\n",
    "    existent_json_fit_files = search_usable_fit_files(directory=jsons_directory, extension=\".json\")\n",
    "    fit_files_to_add = compare_files(usable_fit_files, existent_json_fit_files)\n",
    "    print(\"Adding \" + str(len(fit_files_to_add)) + \" files\")\n",
    "\n",
    "    for fitfile in fit_files_to_add:\n",
    "        json_fit_file = fitfile + \".json\"\n",
    "        os.system(\"fitjson --pretty -f=record -o {0} {1}\".format(os.path.join(jsons_directory, json_fit_file), os.path.join(fit_directory, fitfile))) #Could not run subprocess well with this kind of command, os os.system solves it\n",
    "\n",
    "def obtain_interesting_chunks(my_json):\n",
    "    \"\"\" Returns only the chunks that are necessary for the dataset, avoiding unnecesary or definition frame_types \"\"\"\n",
    "\n",
    "    chunks_to_save = []\n",
    "    for chunk in my_json:\n",
    "        try:\n",
    "            if chunk[\"frame_type\"] == \"data_message\":\n",
    "                chunks_to_save.append(chunk['fields'])\n",
    "        except Exception as e:\n",
    "            print(\"Excepted in chunk, \", e)\n",
    "    \n",
    "    return chunks_to_save\n",
    "\n",
    "def convert_interesting_chunks_to_dataframe(interesting_chunks, training):\n",
    "    \"\"\" Returns necessary records in object format, for better future convertion purposes \"\"\"\n",
    "\n",
    "    custom_records_object = []\n",
    "    for record in interesting_chunks:\n",
    "        custom_record_object = {element['name']: element['value'] for element in record}\n",
    "        custom_record_object.update({\"training\": training})\n",
    "        custom_records_object.append(custom_record_object)\n",
    "    return custom_records_object\n",
    "\n",
    "def open_json(thejson):\n",
    "    \"\"\" Returns an opened JSON \"\"\"\n",
    "\n",
    "    with open(thejson) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def append_dataframes(dataframes_of_trainings):\n",
    "    \"\"\" Returns a unique dataframe from a list of dataframes \"\"\"\n",
    "\n",
    "    return pd.concat(dataframes_of_trainings, ignore_index=True)\n",
    "\n",
    "def obtain_dataframe_from_jsons(directory):\n",
    "    \"\"\" Returns a unique dataframe to work with, orchestrating from JSON opening to that final dataset\"\"\"\n",
    "    \n",
    "    dataframes_of_trainings = []\n",
    "    for currentjson in os.listdir(jsons_directory):\n",
    "        openedjson = open_json(os.path.join(jsons_directory, currentjson))\n",
    "        interesting_chunks = obtain_interesting_chunks(openedjson)\n",
    "        custom_records_object = convert_interesting_chunks_to_dataframe(interesting_chunks, os.path.join(directory, currentjson))\n",
    "        dataframes_of_trainings.append(pd.DataFrame([x for x in custom_records_object]))\n",
    "    return append_dataframes(dataframes_of_trainings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 files\n",
      "0:00:00.001001\n",
      "0:00:00.644682\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "momento1 = datetime.datetime.now()\n",
    "obtain_new_files_in_folder_json_format()\n",
    "print(datetime.datetime.now() - momento1)\n",
    "momento1 = datetime.datetime.now()\n",
    "dataframe = obtain_dataframe_from_jsons(jsons_directory)\n",
    "print(datetime.datetime.now() - momento1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.659350\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "momento1 = datetime.datetime.now()\n",
    "dataframe = obtain_dataframe_from_jsons(jsons_directory)\n",
    "print(datetime.datetime.now() - momento1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                    14663\n",
       "position_lat                 14663\n",
       "position_long                14663\n",
       "distance                         0\n",
       "time_from_course                 0\n",
       "speed                        14663\n",
       "compressed_speed_distance        0\n",
       "heart_rate                   14663\n",
       "enhanced_altitude            14663\n",
       "altitude                     14663\n",
       "enhanced_speed               14663\n",
       "power                        14663\n",
       "grade                            0\n",
       "cadence                      14663\n",
       "resistance                       0\n",
       "cycle_length                     0\n",
       "temperature                      0\n",
       "training                     14663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
